---
title: "CS5801 Coursework Template Proforma"
author: '2039499'
output: rmarkdown::github_document
version: 1
---


```{r}
suppressMessages(library(e1071)) 
suppressMessages(library(tidyverse))
suppressMessages(library(geoR))
suppressMessages(library(rcompanion))
suppressMessages(library(ggpubr))
suppressMessages(library(cowplot))
suppressMessages(library(rpart))
suppressMessages(library(rpart.plot))
suppressMessages(library(caret))
suppressMessages(library(validate))
```

# 1. Organise and clean the data

## 1.1 Subset the data into the specific dataset allocated
 
```{r}
#load the rda file
load(file = "CS5801_data.rda")

# Create a subset of the data with two teams based on the last two digits of my student ID (99 which becomes 90)
my_teams <- subset(CS5801.data, teamID.x=="KCA" | teamID.x=="BOS")

# Make a copy of the original dataframe that we can check back when necesssary after making any changes
df_copy <- subset(CS5801.data, teamID.x=="KCA" | teamID.x=="BOS")
```

## 1.2 Data quality analysis

# Implementation

1.
```{r}
#Examine the data structure and make sure the data has been read in correctly
str(my_teams)

#it is good practice to quickly eyeball the dataframe
head(my_teams)

#converting hit.ind into a factor
my_teams$hit.ind <- as.factor(my_teams$hit.ind)

#removes the extra levels from teamID
my_teams$teamID.x = droplevels(my_teams$teamID.x)

#convert hit.ind 0 into a no and hit.ind 1 into a yes
recode <- c(no = 0, yes = 1)
my_teams$hit.ind <- factor(my_teams$hit.ind, levels = recode, labels = names(recode))

#check for missing values
colSums(is.na(my_teams))
```

2.
```{r}
#after viewing the dataset salary has been read in under scientific notation - the following code removes it
options(scipen = 999)

#change column names to make data more intuitive
colnames(my_teams)[3] <- 'games'
colnames(my_teams)[4] <- 'runs'
colnames(my_teams)[5] <- 'hits'
```

3.
```{r}
#confirming there are 3 values for bats - both arms, left arm and right arm
table(my_teams$bats)

#to examine the data and help spot outliers
summary(my_teams)

#checks for duplicated vales
duplicated(my_teams$playerID)

#finds the name of the player that is duplicated
my_teams$playerID[duplicated(my_teams$playerID)]

#create a new dataframe with the duplicate rows removed
my_teams_1 <- my_teams[!duplicated(my_teams$playerID), ]
```

4.
```{r}
#I have created a new dataframe by using the transform function to replace negative values with NA. 
my_teams_2 <- transform(my_teams_1, RBI = ifelse(RBI < 0, NA, RBI))

View(my_teams_2)
#check constraints
val.check <- check_that(my_teams_2, 
                         age > 16 & age < 50,
                         height > 60,
                         AB >= hits,
                         career.length < age)

#we plot the data test to see if our checks failed or passed
barplot(val.check)
```

5.
```{r}
#any player under 60 inches will be converted into a NA value - I create a new dataset with the imputed value
my_teams_3 <- transform(my_teams_2, height = ifelse(height < 60, NA, height))

#replace values where career length is greater than age with NA
my_teams_4 <- transform(my_teams_3, career.length = ifelse(career.length < age, career.length, NA))
```

6.
```{r}
#helps us find which row this value is in
which(my_teams_4$birthDate == '2002-06-17')

#converts our value into NA
my_teams_4$birthDate[70] <- NA
```

7.
```{r}
#examine salary
summary(my_teams_4$salary)

#any salary under 300,000 will be converted into a NA value (reference_7)
my_teams_5 <- transform(my_teams_4, salary = ifelse(salary < 300000, NA, salary))
```

8.
```{r}
#remove birthdate as it is redundant in our model as we have age
my_teams_6 <- subset(my_teams_5, select = -birthDate )

#create a new variable hitRate
my_teams_6$hitRate <- my_teams_6$hits/my_teams_6$AB

#convert NaNs to 0
my_teams_6$hitRate[is.nan(my_teams_6$hitRate)]<-0

#remove hit.ind
my_teams_7 <- subset(my_teams_6, select = -hit.ind)

#at this point I can omit the rows with missing values
my_teams_clean <- na.omit(my_teams_7)
```

## 1.3 Data cleaning  

1. From comparing the structure to our metadata adendum I have  identified two immediate problems with how our data has been read in by R - hit.ind should be a factor with two levels and teamID.x should be a factor with two levels. It is important for our analysis to correct these as we may want to understand the effects of each level on a variable. I removed them using the droplevels() function so they do not harm our analysis. (reference_12)
  
I used the str() function to look at the structure of the data and ensure text variables are stored as text and numeric variables as number. (reference_13). R has read in the rest of the data correctly assigning numeric, char, Factor and Data appropriately. 

Recoded the factors of hit.ind from 0(no hit) & 1(hit) into 'no' and 'yes' to make the variable more readable and intuitive (reference_13).

2. After viewing the data I noticed salary was in scientific notation which I removed to make it easier for us to understand the numbers we are working with.
   I decided to make our dataset more intuitive and readable by changing a few of the column names. 

3. From the summary function I have spotted possible issues with:
   i) RBI - having negative values (must be positive - set out in metadta)
   ii) height - having a min value of 38 inches - possible outlier.
   iii) salary - having a min value of 515 - possible outlier.
   iv) birthDate - having a max value of 2002-06-17 - possible outlier.
   v) career.length -  having a max value of 35.6372 - possible outlier.
   
I also checked for missing values and duplicated values. I use the duplicated() function with player.id and found two players - "pedrodu01" "moralke01" - that were duplicated. I removed the duplicates from our data. (reference_14). 

When I make any changes to the dataframe, I will create another dataframe and not keep editing the original to make our code and data re-traceable and easier to correct if any mistakes are made.

4. After checking the metadata I have performed the following checks for referential constraints using the validate package (reference_12):
   i) age is older than 16 and younger than 50.
   ii) Height is greater than 60 inches (average height is 72)
   iii) AB must be greater or equal to hits - as the player cannot hit without having the opportunity to hit.
   iv) career length must be less than age.

5. Height has an outlier of 38 inches - It it safe to assume this is an error as 38 inches is 3 foot tall which is shorter than the shortest player in baseball history    (note_2 & reference_1) 

At this stage I have decided to convert these outliers to NA - NA is a special character in R which will represent a missing value. The benefits of using this character is the ability to use functions such as is.na to detect NA's. At a later stage I will decide what to do with these NA's -  deletion or imputation.(reference_13)
   
'Outliers do not mean errors' (reference_13) - they could be interesting edge cases and dont necessarily need to be removed, however, in our cases each outlier has been proven to be an error/implausible which is why I have convereted them to NA's.
   
6. Another obvious inconsistency is taking a players birthday and adding their age to make sure it does not pass 2020. Our dataset is small enough for me to eyeball and see that only one player fails this constraint which is our outlier on Birthdate. As the age falls well within our datasets range but the Birthdate falls well outside I have assumed that the error lies in birthDate and will now convert it into NA.
  
7. As I am not familiar with baseball players salaries in the US, our dataset having such a large range made me feel the need to consult outside references to ensure the salary figures are plausible.

- By checking I was able to determine the mean salary is suitable (reference_2)
- I was able to determine that our maximum salary is suitable as it falls well below the max salary of any players (reference_3)
- I was also able to determine that our outlier must be incorrect data as the minimum MLB salary from 2003-2020 was $300,000 (reference_4). Seeing as this player has played over a year we can safely assume this is an error in our dataset.
   
8. I removed birthDate as it is superfluous given we have Age. I also explored creating a new variable hitRate dividing the number of hits by the opportunities to hit. I wanted to explore if this would be a good predictor for salary. The result was many NaN values as we are diving in many cases by 0 so I converted these to 0.

I removed hit.ind as whether a player makes a hit in the 2015 season or not would not impact their salary for the 2015 season, if hit.ind was from the previous year then it would make sense to include in our model. I believe it is safe to assume salaries of the 2015 season are decided before the 2015 season starts.

I will treat our missing values with case wise deletion as it should not be problematic as we only have a few cases of missing variables - specifically 7. I decided against imputation methods(mean,regression etc) as I do not know for certain the values are missing at random, moreover, when building regression models I do not want to affect the dispersion or variance of our data.

# 2. Exploratory Data Analysis (EDA)

## EDA and summary of results  

I checked the data visually using ggplot to build different graphs.

All of the histograms below show a rough bell curve implying normality in our variables: games, weight, height, career.length and age.
```{r}
#to remind me what data types I am working with
str(my_teams_clean)

#histogram for games played
ggplot(my_teams_clean, aes(x = games)) + geom_histogram(binwidth = 5, fill = 'steelblue') + ggtitle('Number Of Games Played') + xlab('Games') + ylab('Count') + theme_classic()

#histogram for career length of players
ggplot(my_teams_clean, aes(x = career.length)) + geom_histogram(binwidth = 0.5, fill = 'steelblue') + ggtitle('Career Length of Players') + xlab('Lenght In Years') + ylab('Count') + theme_classic()

#histogram for age of players
ggplot(my_teams_clean, aes(x = age)) + geom_histogram(fill = 'steelblue') + ggtitle('Age of Players') + xlab('Age In Years') + ylab('Count') + theme_classic()
```


```{r}
#histogram for the salary of players
ggplot(my_teams_clean, aes(x = salary)) + geom_histogram(fill = 'steelblue') + ggtitle('Salary of Players') + xlab('Salary In Dollars') + ylab('Count') + theme_classic()
```

```{r}
#scatterplot of salary vs career length by team
ggplot(my_teams_clean, aes(x = salary, y = career.length )) + geom_point(aes(color = teamID.x)) + ggtitle('Salary Vs Career Length by Team') + xlab('Salary') + ylab('Career Length in Years') + theme_classic()

#scatterplot of salary vs games played by team
ggplot(my_teams_clean, aes(x = salary, y = games )) + geom_point(aes(color = teamID.x)) + ggtitle('Salary Vs Games Played by Team') + xlab('Salary') + ylab('Games Played') + theme_classic()

#scatterplot of salary vs hits length by team
ggplot(my_teams_clean, aes(x = salary, y = hits )) + geom_point(aes(color = teamID.x)) + ggtitle('Salary Vs Hits by Team') + xlab('Salary') + ylab('Hits') + theme_classic()

```

With the help of boxplots, we are able to understand the location, dispersion and skewness of the dataset.
```{r}
#boxplot of salary vs team
ggplot(my_teams_clean, aes(x = teamID.x, y = salary)) + geom_boxplot(aes(fill = teamID.x))  + ggtitle('Salary by Team') + xlab('BOS VS KCA') + ylab('Salary') + theme_classic()

#boxplot of games played per team
ggplot(my_teams_clean, aes(x = teamID.x, y = games)) + geom_boxplot(aes(fill = teamID.x))  + ggtitle('Games played per Team') + xlab('BOS vs KCA') + ylab('Games') + theme_classic()

#boxplot of career length per team
ggplot(my_teams_clean, aes(x = teamID.x, y = career.length)) + geom_boxplot(aes(fill = teamID.x))  + ggtitle('Career Length per Team') + xlab('BOS vs KCA') + ylab('Years') + theme_classic()
```



## Additional insights and issues

I will now create a numeric subset of our data allowing us to use the pairs function which helps us multi-collinearity in our data.
```{r}
#create a subset with only the continuous explanatory variables
my_teams_cont <- subset(my_teams_7, select = c('games', 'runs', 'hits', 'AB', 'RBI', 'weight', 'height', 'salary', 'career.length', 'age', 'hitRate'))

#when we have multiple continuous variables we can use the pairs function to graph all the data looking for correlations
pairs(my_teams_cont, panel = panel.smooth)
```

Multi-collinearity occurs when two explanatory variables are highly correlated - we can detect this using our pairswise plot. If both are used in our model it makes it difficult to interpret the role of each one so we choose one and remove the other. We can see that there is a positive correlation between each pairing of games, runs, hits, AB and RB which is to be expected as the more games you play allows you chances for more runs and hits. I will remove one variable at a time and see how it effects our model.

We can see again the positive correlation between salary and career.length.

# 3. Modelling

## 3.1 Build a model for player salary

# Plan

When deciding on which model to use, our first step is to recognize what type of data Our dependent variable and explanatory variables are. In this dataset our dependent variable is salary which is numeric continuous. Our explanatory variables are a mixture of numeric and categorical. Therefore we will model our data using ANCOVA.

When performing model analysis we make assumptions on our data
- randomly sampled
- homooscedasticity (homogneity of variance)
- normal errors
- independent errors

So we will fit our initial model and then remove our highly correlated explanatory variables one by one. Once that is complete I will use the step function to find the minimal adequate model based on the lowest AIC score. I will examine our final model using residual plots. If the residual plots look okay then we are fine however if they do not we will need to look into transforming our data. We know already from our EDA that some of are data is heavily skewed/not normal. This may present issues and lead to the need for transformations.

# Implementation
```{r}
#firsly build a maximal model including all the possible explanatory variables
model <- lm(salary~games+runs+hits+AB+RBI+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_clean)
summary(model)

#diagnostic plots
plot(model)

#removed AB
model_2 <- lm(salary~games+runs+hits+RBI+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_clean)
summary(model_2)

#removed RBI
model_3 <- lm(salary~games+runs+hits+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_clean)
summary(model_3)

#removed games
model_4 <- lm(salary~runs+hits+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_clean)
summary(model_4)

#removed hits
model_5 <- lm(salary~games+runs+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_clean)
summary(model_5)

#removed runs
model_6 <- lm(salary~games+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_clean)
summary(model_6)
plot(model_6)
```

We then use the step function to help find our minimal adequate model
```{r}
step(model_6)

final_model <- lm(formula = salary ~ games + career.length + teamID.x, data = my_teams_clean)

summary(final_model)
plot(final_model)
```

## 3.2 Critique model using relevant diagnostics

*Looking at our model*
Our final model is $$salary = -157881 + (22993 \times games) + (843051 \times career.length) - (2666045 \times TeamKCA)$$

This means that for every incremental increase of
- games, then a players salary goes up by $22,993.
- year played then a players salary goes up by $843,051
and that if a player plays for KCA as opposed to BOS then their salary decreases by $2,666,045

*Looking at our summary*
- There is a problem with our residuals - residuals should ideally be symmetrical so we would want Q1 and Q3, Min and Max to be equidistant from 0 and the median to be closer to 0.
- We also learn that only approx 43% of the variance is explained by the model - our R^2 value. This value is low indicating a poor model.
- Our R^2 is significant determined by a significant F value. The F-ratio tells us if the variance explained by our model is significantly different from the one explained by the errors.
 - All of our coefficients are significant at the 1% level, other than games (which is significant at the 5% level). A significant p-value for our coefficients means they will give us a reliable estimate for salary.
 
*Looking at our diagnostic plots*
plot 1 - residuals vs fitted
- ideally this should look random, if there are some trends this indicated a problem with the model assumptions. 
- As we can see there is a grouping of points suggesting we do not have equal variance.

plot 2 - Q-Q plot
- this should be a straight line if the errors are normally distributed
- an S shape or banana shape indicated a different model needs to be fitted
- in our plot the errors are not on the line and follow more of an s-shape suggesting the necessity of a transformation

This all indicates we may need to look for a better model or that some of our assumptions required for ANCOVA are false (reference_11).

False assumptions include:
- constant variance - shown to be false in our diagnostic plots
- nonnormality - our dependent variable salary and many explanatory variables are not normal.
- independence in our Y-variable (salary) - I believe this assumption to be incorrect as players salaries are not fully independent of each other. There is a minimum salary of around $300,000 to which our mode leans to - This minimum was set in 2002 (reference_7)
- outliers - MLB salaries have a minimum but no maximum which allows players to have abnormally large salaries. (reference_7)

A weakness to our model I have identified is incompleteness - missing explanatory variables. One variable I am surprised to see missing from our data is player position. I felt it necessary to improve my knowledge about baseball, from my research I was able to determine that 'Starting pitchers and first basemen are the highest paid in MLB'. I believe that adding 'player_position' as a variable would strengthen our model and the absence of it is a critical weakness of our model. (reference_6).

## 3.3 Suggest improvements to your model

Statistical tests depend on the assumption of normality - significant skewness and kurtosis implies are data is not normal therefore we should apply some sort of transformation to make the data normal. (reference_8)

Coupling the evidence from the diagnostic plots and our preliminary EDA it is evident that transformation of the explanatory variables are needed. It is our last resort to transform our dependent variable as this makes explaining our model more difficult so we will start by transforming our explanatory variables.

I will apply Tukeys Ladder to find a suitable transformation for our variables. (reference_9)
```{r}
#normality check
hist(my_teams_clean$career.length)
hist(my_teams_clean$games)

#tukeys ladder function to help us find a suitable transformation
transformTukey(
  my_teams_clean$career.length,
  start = -10,
  end = 10,
  int = 0.025,
  plotit = TRUE,
  verbose = FALSE,
  quiet = FALSE,
  statistic = 1,
  returnLambda = FALSE
)

#tukeys ladder function to help us find a suitable transformation
transformTukey(
  my_teams_clean$games,
  start = -10,
  end = 10,
  int = 0.025,
  plotit = TRUE,
  verbose = FALSE,
  quiet = FALSE,
  statistic = 1,
  returnLambda = FALSE
)

#create a new dataset for our transformed variables
my_teams_transformed <- my_teams_clean

#transform career length
my_teams_transformed$career.length <- (my_teams_transformed$career.length)^0.6

#transform games
my_teams_transformed$games <- (my_teams_transformed$games)^0.325
```

I will now re-create our model using our transformed variables.

```{r}
#firstly build a maximal model with highly correlated explanatory variables removed
model_transformed <- lm(salary~games+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_transformed)

summary(model_transformed)

#check diagnostic plots
plot(model_transformed)

#use the step function to find our final model
step(model_transformed)

#final model taken from our step function
model_transformed_2 <- lm(formula = salary ~ games + weight + career.length + teamID.x, data = my_teams_transformed)

summary(model_transformed_2)
plot(model_transformed_2)
```

*Looking at our diagnostic plots*
Our plots do not show significant improvement. I will now transform our dependent variable salary.

Salary has a sever positive skew - 1.22. After applying both Tukey's Ladder and log transformations to salary I found that using a log transformation produced the better result for our model in terms of R^2 so I choose to use log.
```{r}
#visualise salary with a density curve overlayed
gghistogram(my_teams_clean, x = "salary", y = "..density..", fill = "steelblue",bins = 20, add_density = TRUE) + ggtitle('Salary Histogram with Density Curve')

#we can use the skewness function found in the e1071 library
skewness(my_teams_clean$salary, na.rm = TRUE)
kurtosis(my_teams_clean$salary)

#from the output, the significant p-value tells us that salary is not normally distributed
shapiro.test(my_teams_clean$salary)

#transform salary
my_teams_transformed$salary <- log(my_teams_transformed$salary)

#create a quantiles-quantiles plot to examine the change in normality
ggqqplot(my_teams_clean$salary)
ggqqplot(my_teams_transformed$salary)

model_transformed_3 <- lm(salary~games+weight+height+career.length+bats+age+hitRate+teamID.x, data = my_teams_transformed)
summary(model_transformed_3)
step(model_transformed_3)

model_transformed_final <- lm(formula = salary ~ games + career.length, data = my_teams_transformed)
summary(model_transformed_final)
plot(model_transformed_final)
```

*Looking at our diagnostic plots*
Our diagnostic plots look the best for this model.

*Looking at our model*
Our final model is $$log(salary) = 12.00478 + (0.24763 \times games) + (0.68547 \times career.length)$$
We can see that this model hasn't included teamID - a significant covariate from our non-transformed model.

*Looking at our summary*
- Our residuals look more symmetrical and centered around 0.
- We also learn that 0.4913 of the variance is explained by the model compared with 0.4394 from our previous model.
- Our F-statistic is larger than in our previous model and significant.
- Our coefficients are all significant.

Overall our R^2 is still very low -  this model could be argued to be a better fit to our data, but transforming Y makes the interpretation of our results difficult. Going by rules of Occams Razor and Parsimony, I would keep things simple and stick with our previous model, however both models do not do a good job of predicting salary. 

# 4. Extension work

## 4.1 Model the likelihood of a player having scored a Hit (using the hit.ind variable provided).

#Plan

- Our dependent variable is binary - 'no' or 'yes' - we will use a GLM model to help us model the data, specifically logistic regression - which will help us understand how the explanatory variables affect the probability of a 'no' or a 'yes' in hit.ind.
- I will perform numerical and graphical explorations of the data - summary and boxplots for example
- We have the knowledge of collinearity from our last EDA so we do not need to check again here, however, if we didn't then I would re-perform the pairs.plot and using scatter plots checking for linearity.
- I will then build a maximal model and use the step function to find a minimal model

I will use the dataset my_teams_6 that includes hit.ind variable and then clean the dataset by removing the NA values. I have removed hitRate as it is a factor created using hit.ind our dependent variable.

```{r}
#remove NA values
my_teams_hit <- na.omit(my_teams_6)

#remove hitRate
my_teams_hit <- subset(my_teams_hit, select = -hitRate)

#confirm the dependent variable is binary
table(my_teams_hit$hit.ind)

#creates a table of team and hit.ind with the columns summed
addmargins(table(my_teams_hit$teamID.x, my_teams_hit$hit.ind))
```

We can then start to explore visually

From the boxplots below we learn that
- Players earning larger salaries are more likely to have made a hit
- Players that play more games are more likely to have made a hit
- Players age does not seem to have a significant effect either way
- Players career length does not seem to have a significant effect either way

```{r}
#boxplot of salary vs hit.ind
ggplot(my_teams_hit, aes(x = hit.ind, y = salary)) + geom_boxplot(aes(fill = hit.ind))  + ggtitle('Salary by Hit.Ind') + xlab('Hit.Ind') + ylab('Salary') + theme_classic()

ggplot(my_teams_hit, aes(x = hit.ind, y = games)) + geom_boxplot(aes(fill = hit.ind))  + ggtitle('Games by Hit.Ind') + xlab('Hit.Ind') + ylab('Games') + theme_classic()

ggplot(my_teams_hit, aes(x = hit.ind, y = age)) + geom_boxplot(aes(fill = hit.ind))  + ggtitle('Age by Hit.Ind') + xlab('Hit.Ind') + ylab('Age') + theme_classic()

ggplot(my_teams_hit, aes(x = hit.ind, y = career.length)) + geom_boxplot(aes(fill = hit.ind))  + ggtitle('Career Length by Hit.Ind') + xlab('Hit.Ind') + ylab('Career Length') + theme_classic()
```
We know from our previous model we have highly correlated pairs of explanatory variables so as before I will remove AB, RBI, hits and runs leaving just games.

Note that there are no diagnostic plots in logistic regression as the assumptions that we were checking for in linear models are not relevant.

```{r}
#we create a maximal model
logit.model <- glm(hit.ind~games+weight+height+career.length+bats+age+teamID.x+ salary, data = my_teams_hit, family = binomial)
summary(logit.model)

#AIC step function model 
step(logit.model)

#select the MAM produced by the step function
logit.model.step <- glm(formula = hit.ind ~ games + bats + age, family = binomial, data = my_teams_hit)

summary(logit.model.step)
```

From the summary we see age is not significant and therefore not a good predictor so I remove it and create our final model

```{r}
#final model is the step model with age removed as it is not significant meaning it is a bad predictor
logit.model.final <- glm(formula = hit.ind ~ games + bats, family = binomial, data = my_teams_hit)

summary(logit.model.final)
```

*From the Summary we can see*
- We can see that this model has significant coefficients.
    Number of games played is significant at the 1% level
    Batting with a left hand is significant at the 5% level
    Batting with a right hand is not significant
    
- Deviance being a measure of the goodness of fit of our generalised linear model. Our residual deviance is lower than our Null deviance indicating the addition of our predictors helps us make better predictions for hit.ind. (reference_16)

For bats = L:
$log(\frac{p}{1-p})=-0.47+0.0048 \times \text{games} - (3.17 \times 1) -(1.82 \times 0)$

For bats = R:
$log(\frac{p}{1-p})=-0.47+0.0048 \times \text{games}- (3.17 \times 0) -(1.82 \times 1)$

```{r}
#the coefficients are the same as in linear models except they are in terms of the log(odds) so we exponent them to return them to regular values
exp(coef(logit.model.final))

#odds ratio of having a hit
exp(cbind(OR=coef(logit.model.final), confint(logit.model.final)))
```
And we interpret the odds ratio as:
- Playing more games increases your odds of having a hit
- Hitting with only your left or right hand lowers your odds of having a hit

```{r}
#predict the probability of hit.ind from the model and add it to our dataset
my_teams_hit$phit<-predict(logit.model.final, type="response")
head(my_teams_hit)
```

```{r}
#to draw a graph with our predictions (reference 15)
predicted.data <- data.frame(probability.of.hit.ind = logit.model.step$fitted.values, hit.ind = my_teams_hit$hit.ind)

predicted.data <- predicted.data[order(predicted.data$probability.of.hit.ind, decreasing = FALSE),]

predicted.data$rank <- 1:nrow(predicted.data)

ggplot(data = predicted.data, aes(x= rank, y=probability.of.hit.ind)) + geom_point(aes(color = hit.ind), alpha =1, shape = 4, stroke = 2) + xlab('index') + ylab('Predicted probability of getting a hit')
```
This graph shows us that most of the players predicted to get a hit (if we set our threshold to be > 0.5) did and most players that were predicted not to get a hit didn't, however there are cases several cases where prediction and result did not match questioning the strength of our model.

Another approach is to use a Decision tree (reference_17)

```{r}
dtree <- rpart(hit.ind~games+age, data = my_teams_hit)
rpart.plot(dtree)
```

From the output we learn that:
- Every player that has played 73 games and above has a hit.
- From then we learn any player that has played less than 73 games and is under 30 years old has not made a hit.
- Any player over 30 and played less than 28 games has not made a hit while players who have played between 28 and 72 games over 30 have made a hit.

We can then use a confusion matrix (reference_18) to test the strength of our model.

```{r}
pred = predict(dtree, type='class')
confusionMatrix(pred, my_teams_hit$hit.ind)
```

The diagonal from top left to bottom right in the prediction matrix shows us how many were correctly classed - 31 for 'no' and 29 for 'yes'. The other diagonal shows us the false negatives and false positives. Our accuracy is 83% for this model.

We can compare this model with our logit model
```{r}
#create my_teams.hit.c converting 'yes' and 'no' back to 0 and 1
my_teams_hit$hit.ind.c <- as.numeric(ifelse(my_teams_hit$hit.ind=="no",0,1))

#our logit model created earlier
logit.model <- glm(hit.ind.c~games+bats, family = binomial, data = my_teams_hit)

#create our predicted data set
pdata <- predict(logit.model, type = "response")

#create a confusion matrix while turning the numeric predictions of pdata into a vector of class predictions using the cutoff 0.5
confusionMatrix(data = factor(as.numeric(pdata>0.5)), reference = factor(my_teams_hit$hit.ind.c))
```

Here we see the accuracy of our logit model to be 73% compared to our decision tree model at 83%, therefore I would stick to the decision tree model for predicting if a player has made a hit or not.

# References  
Note: Some references in the data will not be in order. This is as I made the decision to present a clean and polished report. I understand that data analysis is an iterative cycle and often throughout this project I have learned things and gone back and made changes. I could have explained each stage as it happened but I decided for this project to present a clean and structured chronological order of data analysis as I believe it is easier to understand it this way. The reference list will however hint at the stage I discovered new ideas/problems.

reference_1: https://bleacherreport.com/articles/773184-size-doesnt-matter-the-top-10-smallest-in-mlb-history
reference_2: https://www.statista.com/statistics/236213/mean-salaray-of-players-in-majpr-league-baseball/
reference_3: https://www.statista.com/statistics/533971/highest-paid-mlb-players/
reference_4: https://www.statista.com/statistics/256187/minimum-salary-of-players-in-major-league-baseball/
reference_5: https://bookdown.org/martin_shepperd/ModernDataBook/C4-Intro.html
reference_6: https://www.businessinsider.com/chart-mlbs-highest-paid-positions-2014-7?r=US&IR=T
reference_7: https://www.baseball-reference.com/bullpen/Minimum_salary#:~:text=The%20minimum%20salary%20is%20the,raised%20by%2050%25%20to%20%24300%2C000.
reference_8: https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm
reference_9: https://rdrr.io/cran/rcompanion/man/transformTukey.html
reference_10: https://help.gooddata.com/doc/en/reporting-and-dashboards/maql-analytical-query-language/maql-expression-reference/aggregation-functions/statistical-functions/predictive-statistical-use-cases/normality-testing-skewness-and-kurtosis#:~:text=As%20a%20general%20rule%20of,the%20distribution%20is%20approximately%20symmetric.
reference_11: https://www.quality-control-plan.com/StatGuide/ancova_ass_viol.htm#Nonconstant%20variance%20of%20Y
reference_12: https://bookdown.org/martin_shepperd/ModernDataBook/C5-DataQualCheck.html
reference_13: https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf
reference_14: https://www.datanovia.com/en/lessons/identify-and-remove-duplicate-data-in-r/
reference_15:'https://www.youtube.com/watch?v=C4N3_XJJ-jU&ab_channel=StatQuestwithJoshStarmer'
reference_16: https://www.theanalysisfactor.com/r-glm-model-fit/
reference_17: https://data-flair.training/blogs/r-decision-trees/
reference_18: https://www.datacamp.com/community/tutorials/confusion-matrix-calculation-r

# Notes

Note_1: After making any changes to the dataset I than check the change has been done correctly by re-examining the data as you will see, however, going forward I will leave all similar checks out for the purpose avoiding repetitive code.

Note_2:  I have made an assumption that this dataset is from MLB players 2015 season in the US - I believe it is safe to do so given the following:
1) hit.ind addendum states the data is from the 2015 season.
2) The teams are from the US (also confirmed in our discussion board)
3) Salaries have reached 19 million - only applicable to MLB.
Therefore when checking if data is plausible it is fair to consult outside sources regarding MLB.